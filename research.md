---
layout: default
---

# [](#my-research)My Research

I currently work as a **Postdoctoral Research Associate** at the Interaction Lab, School of Mathematical and Computer Sciences, Heriot-Watt University.


Previously I have been Postdoctoral Research Associate at the [COGNITIVE ROBOTICS LAB](https://corolab.github.io/) in the Department of Computer Science, University of Manchester (United Kingdom), and a Postdoctoral Fellow in Human-Robot Interaction at the [Centre for Robotics and Neural Systems](https://www.plymouth.ac.uk/research/robotics-neural-systems).
<!-- As a researcher, I have focused on Humanoid Robots; Artificial Intelligence; Cognitive Systems; Machine Learning Algorithms and Deep Learning; and Human-Robot Interaction. -->
My general research interests have been predominantly in the area of Human-Robot Interaction (HRI), with a main interest in developing Intelligent and Socially-Aware Assistive Agents. As a researcher, I have focused on Human-Robot Interaction and Social Robotics, Artificial Intelligence, Cognitive Systems, Interactive Task Learning, Machine Learning and Deep Learning.


I have a career spanning multiple fields and research topics, across national boundaries. As a researcher, I have focused on Human-Robot Interaction and Social Robotics, Artificial Intelligence, Cognitive Systems, Machine Learning and Deep Learning. I have 10+ years of experience with robotics research, from the Mechatronics Group at Universidad Simon Bolivar, the RoboticsLab at Universidad Carlos III de Madrid (UC3M), the Centre for Robotics and Neural Systems at University of Plymouth, the COROLAB at the University of Manchester, to the Interaction Lab at Heriot-Watt University. I have also experience from short research placements in Spain (Centre for Automation and Robotics, CSIC), Switzerland (Learning Algorithms and Systems Laboratory (LASA), EPFL), and Italy (Italian Institute of Technology (IIT)). I have extensive experience working on all levels of robotics, from the integration of servos, sensors and microcontrollers, the programming of control software and user interfaces, interfacing with middleware like YARP and ROS, to the development of high-level cognitive architectures, computer vision, machine learning algorithms and frameworks for deep learning, like pytorch, tensorflow and keras. I have worked on several real-world platforms, like the child-size humanoid iCub, the collaborative robots BAXTER and SAWYER, and the social robots ARI, Pepper and NAO; I have additional working experience with the climbing hexapod REST robot, the Giraff robot, the small RoboNova and Bioloid humanoid robots (for competitions), and the fujitsu humanoid robot HOAP-3.



At the center of my research the goal has been directed on two major ideas, developing human in the loop systems, and embodied situated robots. This is evidence on the number of national and European projects I've contributed to, with the aim of developing robotic systems and technologies with beneficial applications to industry, education or care, and improving general well-being for humans.


To unlock the full potential of service and domestic robots, it is essential that they are able to understand information created around them and to generate knowledge, and that they are able to respond adaptively and appropriately to the combination of unexpected events and indeterminate consequences of the real world. Hence, I am pursuing projects involving socially assistive robots in combination with other ongoing work on planning and navigation for human populated environments, conversational agents, emotion recognition, object manipulation and many other research topics in the HRI Lab to provide a bridge between the applications by enabling SARs to fulfil social roles and successfully execute tasks by equipping them with the ability to move, see, hear and communicate in complex and unstructured populated spaces. Robots that can learn from human behavioural skills with a view to interacting with us socially, intelligently and emotionally.



I am interested in exploring topics related to Cognitive Systems, Human-Robot Interactions, Robots for Therapy and Care, Social Robots, Interactive Task Learning, Machine Learning and Neurorobotics. My vision is to deliver robots and autonomous systems that can work with and for humans.



##### Human-Robot Interactions in Social Robots for care, therapy and education.

##### Deep Learning for Social Intelligent Robots.

##### Cognitive and Neuro-Robotics.

##### Learning and Adapting Robot Skills.

##### Knowledge Representation.

##### Interactive Task Learning


##### Ethical Issues in Robotics.

I am also interested in the ethical issues of using robots and robot ethics.
I co-organize a series of workshops on [Social Robots in Therapy and Care](https://sites.google.com/view/ws-srec/social-robots-in-therapy-and-care) at the 13th and 14th ACM / IEEE International Conference on Human-Robot Interaction (HRI);  with a focus on autonomy and ethical challenges. The workshop aims at understanding how increasing the autonomy of robots might affect therapies as well as the design and ethical challenges of health-care robots.


# [](#projects)Projects

<!-- I have a career spanning multiple fields and research topics, across national boundaries. As a researcher, I have focused on Machine Learning Algorithms and Artificial Intelligence, Cognitive Systems and Human-Robot Interaction, taking part in a number of both, national and European projects; implementing various systems and designing and executing different study scenarios and experiments, both in simulation and with real physical robots. -->

I have taken part in several, national and European projects with the aim of developing robotic systems and technologies with beneficial applications to industry, education, care, and improving general well-being. In the [ROBOT@CWE (Advanced robotic systems in future collaborative working environments.)](#robotcwe) project, my work focused on the cooperation between humanoid robots and humans, in a human-centred design for industry 4.0. My research on the EPSRC [BABEL (Bio-Inspired Architecture for Brain Embodied Language)](#babel) focused on developing novel neuromorphic systems for cognitive and language processing that will advance the design of new interactive system applications (e.g., autonomous service robots, smart devices, speech interfaces, intelligent transport vehicles). In the [L2TOR (Second Language Tutoring using Social Robots)](#l2tor) project, I worked on how social robots can be used as tutor to young children. The [DREAM](#dream) project researched the development of robot-enhanced therapy for children with autism spectrum disorders. The [MoveCare (Multiple-actOrs Virtual Empathic CARgiver for the Elder)](#movecare) project focused on social robots for independent living. Here a domotic system, smart objects and a robotic platform were integrated to provide, through artificial intelligence, assistance and transparent monitoring to the elder at home.  Currently I work, in the [SPRING (Socially Pertinent Robots in Gerontological Healthcare)](#spring) EU project. My research is focused on developing socially aware robots with the capacity for cognitive interactions, with a particular emphasis into bringing socially assistive robots into gerontological healthcare.



### [](#spring)SPRING

#### SPRING: Socially Pertinent Robots in Gerontological Healthcare

SPRING — Socially Pertinent Robots in Gerontological Healthcare — is an EU H2020-ICT research and innovation action (RIA). Develop a novel paradigm and novel concept of socially-aware robots, and to conceive innovative methods and algorithms for computer vision, audio processing, sensor-based control, and spoken dialog systems based on modern statistical- and deep-learning to ground the required social robot skills. Oliver Lemon and Christian Dondrup are Principal Investigators at Heriot-Watt.

[https://spring-h2020.eu/](https://spring-h2020.eu/)

### [](#movecare)MoveCare

#### MoveCare: Multiple-actOrs Virtual Empathic CARgiver for the Elder

MoveCare integrates an existing robotic platform with a domotic system, smart objects, a virtual community and an activity center, to provide, through artificial intelligence, assistance, activities and transparent monitoring to the elder at home. MoveCare can be tailored to each elder thanks to a modular design. It is completely unobtrusive as MoveCare does not require the elder to wear any particular device. Angelo Cangelosi is Principal Investigator at Manchester.

[http://www.movecare-project.eu/](http://www.movecare-project.eu/)

### [](#dream)DREAM

#### DREAM: Development of Robot-Enhanced therapy for children with AutisM spectrum disorders

Development of Robot-Enhanced therapy for children with AutisM spectrum disorders (ref. FP7-ICT-600915). Integrated Project under the 7th framework programme of the European Union. 4.5 year project, start 1 February 2014. Total budget of 8.6M EUR, with 1.23M EUR for Plymouth. Tony Belpaeme is Principal Investigator at Plymouth. Other partners are Hogskolan I Skovde (Tom Ziemke, Project Coordinator), Vrije Universiteit Brussel, Universitatea Babes Bolyai, University of Portsmouth, De Montfort University and Aldebaran Robotics.

[http://www.dream2020.eu/](http://www.dream2020.eu/)

### [](#l2tor)L2TOR

#### L2TOR: Second Language Tutoring using Social Robots

Second Language Tutoring using Social Robots (3.043M EUR total budget, 544,013 EUR to Plymouth University) project. H2020 project, coordinated by Tony Belpaeme. Other partners University of Tilburg, Bielefeld University, Utrecht University, Koc University, Aldebaran Robotics and QBMT. The L2TOR studies how robots can be used to tutor a second language to young children. L2TOR capitalises on research that shows how social robots have marked benefits over screen-based tutoring technologies.

[http://www.l2tor.eu/](http://www.l2tor.eu/)

### [](#babel)BABEL

#### EPSRC Project BABEL: Bio-Inspired Architecture for Brain Embodied Language​.

BAEL is a new EPSRC project on the computational neuroscience modelling of language and action learning in the humanoid robot iCub, and its implementation in the neuromorphic systems SpiNNAker. It integrates cognitive neuroscience, brain imaging, neuro-computational modelling, and neurorobotic experiments in advancing our understanding of the neuroscience mechanisms supporting language learning.​ ​This project will lead to the design of neuromorphic systems for cognitive and language processing suitable for a wide range of interactive system applications (e.g. autonomous service robots, smart devices, speech interfaces, intelligent transport vehicles).

This project was funded by EPSRC EP/J004561/1 and lasted from August 2012 to March 2017. [http://www.babel-project.org/](http://www.babel-project.org/)

### [](#robotcwe)Robot@CWE

#### European Specific Targeted Research Project ROBOT@CWE: Advanced robotic systems in future collaborative working environments.

The main objective of this project was to research and demonstrate integrative concepts of advanced robotic systems, to be seen as collaborative agents, in various environments working together with humans. We integrated collaborative robotic systems as active agents operated through various control paradigms within working environment clusters. ROBOT@CWE designed suitable architectures and technologies to achieve this goal. A major aspect of the project was human-centred design, especially the assessment of usability, social acceptance, user experience, and societal impact of humanoid robots.

This STREP project was funded by FP6-2005-IST-5 Collaborative Working Environments and lasted from November 2006 to October 2009. [https://cordis.europa.eu/project/rcn/80174_en.html](https://cordis.europa.eu/project/rcn/80174_en.html)


[:arrow_heading_up:](#my-research)
[:leftwards_arrow_with_hook:](javascript:history.back())
